# Tiptap

This is an example component.

```tsx
import { TiptapEditor, TiptapToolbar, useTiptapEditor} from 'ct-tiptap-editor';
import { useState } from 'react';

export default () => {
  const [content, setContent] = useState('');

  const onSave = (value) => {
    console.log('onSave', value)
  }

  const onUpdate = (value) => {
    console.log('onUpdate', value)
  }

  const onImageUpload = (file) => {
    console.log('onImageUpload', file)
  }

  const editorRef = useTiptapEditor({
    content,
    onSave,
    onUpdate,
    onImageUpload
  });

  if (!editorRef) return null;

  return <div style={{ 
    width: '100%', 
    border: '1px solid #ccc'
  }}>
  <div>
    <TiptapToolbar editorRef={editorRef}  />
    <TiptapEditor editorRef={editorRef} onUpdate={onUpdate} content={content} />
  </div>
</div>
}
```


```jsx
import { TiptapReader, useTiptapEditor } from 'ct-tiptap-editor';

export default () => {
  const content='- 上一篇：, 科技爱好者周刊（第 3\n分类 ：\n\n\n- 周刊\n- ⇐\n# 科技爱好者周刊（第 349 期）：神经网络算法的发明者\n\n\n作者：  [阮一峰](http://www.ruanyifeng.com/)\n\n\n日期：  [2025年5月23日](http://www.ruanyifeng.com/blog/2025/05/)\n这里记录每周值得分享的科技内容，周五发布。\n\n\n本杂志 [开源](https://github.com/ruanyf/weekly) ，欢迎 [投稿](https://github.com/ruanyf/weekly/issues) 。另有 [《谁在招人》](https://github.com/ruanyf/weekly/issues/6771) 服务，发布程序员招聘信息。合作请 邮件联系 （ yifeng.ruan@gmail.com ）。\n\n\n\n\n## 封面图\n\n\n\n\n\n北京的护城河公共绿道，位于鼓楼附近。（via  [visuals_china@instagram](https://www.instagram.com/p/DJi3qkuOTZ5/) ）\n\n\n\n\n## 神经网络算法的发明者\n\n\n上周的 [《李飞飞自传》读后感](https://www.ruanyifeng.com/blog/2025/05/weekly-issue-348.html) ，还有后续。\n\n\n那篇文章的结尾是，2012年一支加拿大团队使用神经网络算法，夺得了 ImageNet 比赛冠军。\n\n\n今天就来说说，这支加拿大团队的故事。\n\n\n\n\n\n大家看了就知道了，神经网络算法是怎么诞生的，背后的推手又是谁。\n\n\n（1）杰弗里·辛顿 （Geoffrey Hinton，1947-）\n\n\n\n\n\n辛顿出生于英国，后移居加拿大。他是神经网络算法的奠基人和主要发明者。\n\n\n神经网络的概念，是上世纪40年代后期提出的（提出人不是辛顿）。当时的想法是，既然人类通过神经网络进行思考，那么只要让机器模拟神经网络，机器就能思考了。\n\n\n但是，那只是一个概念，并没有具体的算法。机器怎么模拟思考，人们并不知道。\n\n\n1984年，辛顿在加州大学担任博士后，与两个同事一起提出了反向传播算法。\n\n\n这个算法可以建立多层网络，产生一个输出结果，让神经网络变成了现实，也是后来更高级算法的基础。\n\n\n由于它需要多层计算，后一层在前一层的结果上学习，所以被称为"深度学习"，辛顿因此成为"深度学习之父"。\n\n\n辛顿后来因为这个贡献，获得了图灵奖（2018年）和诺贝尔物理学奖（2024年）。\n\n\n（2）杨立昆 （1960-）\n\n\n\n\n\n杨·安德烈·勒坎（Yann André Le Cun，中文名杨立昆）是法国人。上个世纪80年代，他是多伦多大学博士后。\n\n\n这一时期，辛顿也来到了多伦多大学任教，担任他的指导教师。\n\n\n所以，杨立昆是辛顿的大弟子，继承和发展了辛顿的算法。他的主要成就是，为神经网络引入了卷积算法，并且做出了第一个有实际用途的神经网络。\n\n\n1990年代，他用神经网络识别银行支票的手写数字，成功获得了企业的采用。\n\n\n\n\n\n但是，这个应用也暴露了卷积神经网络的弱点：它需要大量样本的训练，耗费巨大的算力。银行支票只需要识别10个阿拉伯数字，如果是更多样化的场景，当时的计算能力难以做到。\n\n\n学术界因此认为，卷积神经网络只适用特定的、计算量较小的场景，不具备推广的价值。这导致这种算法，以及辛顿和杨立昆，被冷落了二十年。\n\n\n这二十年，杨立昆一直混迹于企业实验室和大学教研室。等到世界重新认识卷积神经网络，他在2018年与辛顿一起获得了图灵奖，现在是 Meta 公司的副总裁和 AI 首席科学家。\n\n\n（3）亚历克斯·克里泽夫斯基 （Alex Krizhevsky，1986-）\n\n\n\n\n\n亚历克斯·克里泽夫斯基是乌克兰人，少年时随家人移民到加拿大。2007年，他进入多伦多大学，成为辛顿的博士生。\n\n\n这时距离杨立昆提出卷积神经网络，已经过去快20年了。辛顿始终没忘记它，他鼓励亚历克斯和稍后要提到的伊尔亚·苏茨克维，使用这种算法，去挑战李飞飞的 ImageNet。\n\n\n亚历克斯就写了一个程序，用 ImageNet 的1500万图片，来训练他的卷积神经网络。但是，计算量太大了，他的个人计算机根本跑不动，他就买了两块 Nvidia 显卡，每天24小时一刻不停地运算。\n\n\n事实证明，卷积神经网络+大训练集+高速计算硬件，超过了其他一切已知的算法。最终，他们的三人团队以巨大优势，夺得了2012年第三届 ImageNet 算法比赛冠军。\n\n\n这件事轰动了业界，各大互联网公司纷纷邀请辛顿和他的学生加入。百度也伸出橄榄枝，邀请辛顿担任首席科学家，但是最后输给了谷歌。\n\n\n2013年，谷歌以4400万美元收购了辛顿成立的空壳公司，将辛顿、亚历克斯、伊尔亚三个人一起招入麾下。\n\n\n2017年，亚历克斯辞职，现在一家创业公司研究 AI 技术。\n\n\n（4）伊尔亚·苏茨克维 （Ilya Sutskever， 1986-）\n\n\n\n\n\n伊尔亚·苏茨克维出生于前苏联，后去了以色列，然后来到加拿大。他是亚历克斯·克里泽夫斯基在多伦多大学的博士同学，也是辛顿的博士生。\n\n\n他与亚历克斯组成团队，共同赢得了2012年的 ImageNet 算法比赛。辛顿作为指导老师，也是团队一员。\n\n\n他在2013年跟随辛顿加入谷歌，2015年辞职，成为 OpenAI 的联合创始人和首席科学家，后来是 ChatGPT 的主要作者之一。2024年，他离开 OpenAI，现在创立了自己的 AI 公司。\n\n\n（5）安德烈·卡帕斯 （Andrej Karpathy，1986-）\n\n\n\n\n\n安德烈·卡帕斯出生于斯洛伐克，15岁随家人来到加拿大，在多伦多大学读完了本科。\n\n\n他跟伊尔亚·苏茨克维很可能大学里就认识。但是，他没在多伦多大学读博士，而是去了斯坦福大学，指导老师就是李飞飞。\n\n\n他的方向也是卷积神经网络，博士期间开设了斯坦福大学第一门深度学习课程，担任主讲。\n\n\n2015年，他跟随伊尔亚一起加入 OpenAI，成为主要研究人员。\n\n\n2017年，他离开 OpenAI，去了特斯拉，担任特斯拉 AI 总监，2022年离职。\n\n\n（6) 总结\n\n\n上面五人是神经网络算法的主要创立者和推动者。没有他们，就不会有今天的 AI 大模型。\n\n\n但是，单单靠他们的算法，AI 不会成功。因为算法需要大量的数据进行训练，而训练需要高速计算的硬件。这三者缺一不可。\n\n\n只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n\n\n历史于是翻开了新的一页，AI 时代正式来临。\n\n\n\n\n## 科技动态\n\n\n（1）一家深圳公司推出了，可能最炫酷的 [树莓派机箱](https://liliputing.com/pironman-5-max-turns-a-raspberry-pi-5-into-a-mini-tower-with-a-transparent-case-rgb-lighting-and-dual-nvme-ssd-support/) 。\n\n\n\n\n\n它自带机箱显示屏、RGB 灯光、风扇、NVMe SSD 扩展板，很适合用作 NAS 和 AI 边缘计算。\n\n\n\n\n\n（2）芬兰尝试在 [驯鹿的鹿角](https://www.smithsonianmag.com/smart-news/avoid-deer-strikes-finland-painting-deer-antlers-reflective-paint-180949792/) ，涂上荧光粉。\n\n\n\n\n\n这是为了方便司机在夜间看到驯鹿，目前每年在芬兰公路上被撞死的驯鹿有4000头。\n\n\n（3）在线会议软件 Google Meet，推出 [实时语音翻译](https://www.engadget.com/apps/google-brings-live-translation-to-meet-starting-with-spanish-174549788.html) ，首先提供西班牙语版本。\n\n\n\n\n\n在线会议时，对方说西班牙语，你听到的却是英语，而且声音、语调和情感‌都不变。\n\n\n（4）意大利开源硬件公司 Arduino，研发出了 [可降解 PCB](https://blog.arduino.cc/2025/04/22/arduino-is-at-work-to-make-bio-based-pcbs/) （电路板），减轻对环境的污染。\n\n\n\n\n\n这种可降解电路板，将电路印刷在植物亚麻材料上，而不是传统的玻璃纤维和树脂。\n\n\n不过，电路板上的铜无法降解，需要在丢弃电路板之前先回收。\n\n\n（5）一家美国创业公司，准备发射卫星，将  [AI 机房建在太空](https://www.ycombinator.com/companies/starcloud) 。\n\n\n\n\n\n它依靠24小时的太阳能供电，也不用担心散热。\n\n\n该公司希望通过这种方法，解决 AI 服务器的耗电和冷却问题。\n\n\n\n\n## 文章\n\n\n1、 [手机的 Linux 桌面环境](https://holdtherobot.com/blog/2025/05/11/linux-on-android-with-ar-glasses/) （英文）\n\n\n作者出门不带笔记本，只带手机，再配上蓝牙键盘和 AR 眼镜。\n\n\n\n\n\n他的安卓手机在获取 root 权限后，通过 chroot 安装了 Linux 发行版，从而可以运行桌面环境。\n\n\n\n\n\n2、 [AI 应用的核心逻辑](https://sketch.dev/blog/agent-loop) （英文）\n\n\n\n\n\n作者提出，AI 应用（AI agent）的核心逻辑只需要9行代码。\n\n\n3、 [浏览器默认屏蔽的端口](https://www.keenformatics.com/ports-that-are-blocked-by-browsers) （英文）\n\n\n\n\n\n你可能不知道，浏览器无法打开下面的网址 localhost:6000 ，原因是6000是浏览器默认屏蔽的端口。\n\n\n4、 [推荐 RustDesk 远程桌面](https://www.xda-developers.com/i-tried-every-method-to-remotely-access-my-pc-this-method-is-the-best/) （英文）\n\n\n\n\n\nMac 电脑访问 Windows 电脑，一种方法就是使用远程桌面，作者推荐远程桌面工具 RustDesk。\n\n\n5、 [HTML <dialog> 的 CSS 技巧](https://cassidoo.co/post/css-for-dialogs/) （英文）\n\n\n\n\n\nHTML 有一个原生的弹窗元素 <dialog> ，本文介绍两个配套使用的 CSS 技巧。\n\n\n6、 [Git 配置详解](https://blog.gitbutler.com/how-git-core-devs-configure-git/) （英文）\n\n\n\n\n\n本文详细解释 Git 配置命令 git config 的几个最常见的设置。\n\n\n\n\n## 工具\n\n\n1、 [Pyrefly](https://github.com/facebook/pyrefly/)\n\n\n\n\n\nMeta 公司发布的 Python 代码的类型检查器，参见 [介绍文章](https://engineering.fb.com/2025/05/15/developer-tools/introducing-pyrefly-a-new-type-checker-and-ide-experience-for-python/) 。\n\n\n2、 [Zen Browser](https://github.com/zen-browser/desktop)\n\n\n\n\n\n新发布的一个开源浏览器，基于 Firefox，国外评价非常高，使用体验好，参见 [介绍文章](https://www.xda-developers.com/zen-browser-better-brave-arc-chrome/) 。\n\n\n3、 [xtool](https://github.com/xtool-org/xtool)\n\n\n\n\n\nXcode 的替代品，在 Linux/Win/macOS 开发 iOS 应用。\n\n\n4、 [Zero Convert](https://nextbconvert.com/)\n\n\n\n\n\n在线批量转换文件，基于 WebAssembly 技术，完全本地完成，还可以编辑图片。（ [@xiaoshangmin](https://github.com/ruanyf/weekly/issues/6864)  投稿）\n\n\n5、 [耗子面板](https://github.com/tnb-labs/panel)\n\n\n\n\n\nGo 语言开发的服务器管理面板。（ [@devhaozi](https://github.com/ruanyf/weekly/issues/6881)  投稿）\n\n\n6、 [Goravel](https://github.com/goravel/goravel)\n\n\n\n\n\nGo 语言的 Web 开发框架，与 PHP 的 Laravel 框架保持一致，方便快速上手。（ [@devhaozi](https://github.com/ruanyf/weekly/issues/6882)  投稿）\n\n\n7、 [OpenSpeedy](https://github.com/game1024/OpenSpeedy)\n\n\n开源的游戏变速工具，通过调整 Windows 系统时间函数来实现游戏速度变化。（ [@game1024](https://github.com/ruanyf/weekly/issues/6884)  投稿）\n\n\n8、 [SimonAKing-Gallery](https://github.com/SimonAKing/AnimatedGallery)\n\n\n\n\n\n后端的 JS 相册应用，瀑布流展示图片，指定图片目录，直接运行即可。（ [@SimonAKing](https://github.com/ruanyf/weekly/issues/6886)  投稿）\n\n\n9、 [Jwno](https://github.com/agent-kilo/jwno)\n\n\n\n\n\n网友开源的 Windows 10/11 平铺窗口管理器，键盘驱动。（ [@agent-kilo](https://github.com/ruanyf/weekly/issues/6891)  投稿）\n\n\n10、 [星河小程序](https://github.com/didi/dimina)\n\n\n\n\n\n滴滴公司开源的跨平台开发框架，支持将小程序打包成为安卓、iOS、鸿蒙和 Web 四个平台的原生 App。（ [@dos1in](https://github.com/ruanyf/weekly/issues/6912)  投稿）\n\n\n\n\n## AI 相关\n\n\n1、 [aTrain](https://github.com/JuergenFleiss/aTrain)\n\n\n\n\n\n一个跨平台、图形界面的自动语音识别工具，基于 Whisper 模型，支持识别50多种语言，参见 [介绍文章](https://www.xda-developers.com/i-switched-from-otter-to-this-self-hosted-audio-transcription-app/) 。\n\n\n2、 [AI Image Editor](https://aiimageeditor.me/)\n\n\n\n\n\n在线的免费图像处理工具，提供多种 AI 功能，比如图片增强、去除水印、风格转换等十几种。（ [@worminone](https://github.com/ruanyf/weekly/issues/6883)  投稿）\n\n\n\n\n## 资源\n\n\n1、 [万物博物馆](https://mayeclair.itch.io/museum-of-all-things)\n\n\n一个跨平台的桌面软件，将维基百科变成一个虚拟博物馆。\n\n\n\n\n\n每件展品与维基百科的一篇文章相对应，墙上的画框就是文章图片，讲解牌就是文章内容。\n\n\n\n\n\n走廊则根据文章的链接通向其他展厅，有几乎无限的展厅可以参观。\n\n\n\n\n\n\n\n## 图片\n\n\n1、 [《星球大战》的机器人](https://www.facebook.com/groups/1740302472949408/permalink/3918177945161839)\n\n\n《星球大战》的第一部电影，拍摄于1976年，里面有一个机器人 R2-D2，会四处走动，做各种动作，还会说话。\n\n\n\n\n\n其实，它根本没那么高科技，拍摄的时候，就是里面藏了一个真人演员。\n\n\n\n\n\n2、 [冰为什么体积大？](https://nautil.us/five-things-we-still-dont-know-about-water-3383/)\n\n\n水变成冰以后，体积会增大10%，密度因此小于水，使得冰可以浮在水面上。\n\n\n那么，冰的体积为什么会增大呢？\n\n\n答案是冰的分子结构，跟水的分子结构不一样。\n\n\n\n\n\n上图左侧是液态水的分子结构，右侧是冰的分子结构。其中，白色节点为氢原子，红色节点为氧原子。\n\n\n可以看到，液态水是紧密聚合的网络结构，冰则是中空的网络结构。也就是说，冰的分子结构不是那么密合，所以体积就变大了。\n\n\n\n\n## 文摘\n\n\n1、 [Slack 公司的 URL](https://blog.jim-nielsen.com/2023/examples-of-great-urls/)\n\n\nSlack 是一家即时通信的软件公司。它的官网有一个"公司介绍"的页面，通常来说该页面的 URL 会是 slack.com/about ，但是 Slack 没有采用这种做法。\n\n\n它将这个页面命名为 is ，并分拆成若干个子页面。\n\n\n所以，"公司介绍"页面的 URL 是 slack.com/is 。\n\n\n子页面的 URL 如下。\n\n\n> - slack.com/is/team-communication\n> - slack.com/is/everything-in-one-place\n> - slack.com/is/wherever-you-are\n\n\n这样的好处是单单看 URL，就知道页面想要传递的信息，URL 本身就是对公司的一种宣传。\n\n\n这种 is 的巧妙做法，后来被广泛借鉴。碰巧的是， is 也正好是一个顶级域名，代表冰岛（iceland）。很多名人就申请了 is 域名，作为个人主页。\n\n\n比如，艺术家杰西卡·希斯切（Jessica Hische）的个人网站，域名就是 jessicahische.is ，她介绍自己的页面 URL 就都是 jessicahische.is/xxx 的形式。\n\n\n\n\n## 言论\n\n\n1、\n\n\n我们很快会跟大家分享一个低调的研究成果。我们会给它起一个比 chatGPT 更好的名字，以防它流行起来。\n\n\n--  [Sam Altman](https://x.com/sama/status/1923104596622246252) ，OpenAI 的 CEO\n\n\n2、\n\n\n加尔定律经常被引用："一个有效的复杂系统，总是从一个有效的简单系统进化而来。"\n\n\n但是，它的推论很少被引用："一个从零开始设计的复杂系统永远不会有效，你必须从一个可以运行的简单系统开始。"\n\n\n--  [Stack Staves](https://www.stackstaves.net/post/2023-12-07-theres-more-to-that/)\n\n\n3、\n\n\n宇宙有两种可能：要么我们是孤独的，要么我们并不孤独。这两种可能性都同样令人恐惧。\n\n\n--  [阿瑟·克拉克](https://www.planetary.org/articles/the-fermi-paradox-where-are-all-the-aliens) ，英国著名科幻小说家\n\n\n4、\n\n\n太阳绕银河系公转一圈需要2.3亿年，上一圈的时候，地球的主宰还是恐龙。\n\n\n--  [Reddit 网友](https://www.reddit.com/r/Paleontology/comments/18wqvba/it_takes_the_sun_230_million_years_to_orbit_once/)\n\n\n5、\n\n\n我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n\n\n最终可能会出现这样一代人，自己的智力很低下，完全依赖于他们不理解的技术，一旦技术崩溃，他们永远无法从头开始重建。\n\n\n--  [尼尔·斯蒂芬森](https://simonwillison.net/2025/May/18/neal-stephenson/#atom-everything) （Neal Stephenson），美国科幻小说家，"元宇宙"一词的创造者\n\n\n\n\n## 往年回顾\n\n\n[创业虽然好，不敢推荐了](https://www.ruanyifeng.com/blog/2024/05/weekly-issue-302.html) （#302）\n\n\n[互联网创业变难了](https://www.ruanyifeng.com/blog/2023/04/weekly-issue-252.html) （#252）\n\n\n[三个有启发的学习方法](https://www.ruanyifeng.com/blog/2022/04/weekly-issue-202.html) （#202）\n\n\n[从北大到技校](https://www.ruanyifeng.com/blog/2021/04/weekly-issue-152.html) （#152）\n\n\n（完）\n### 文档信息\n\n\n- 版权声明：自由转载-非商用-非衍生-保持署名（, 创意共享3.0许可证, ）\n- 发表日期：, 2025年5月23日\n\n## 相关文章\n\n\n- 2025.05.16: 科技爱好者周刊（第 348 期）：李飞飞，从移民到 AI 明星, 这里记录每周值得分享的科技内容，周五发布。\n- 2025.05.09: 科技爱好者周刊（第 347 期）：冷启动的破解之道, 这里记录每周值得分享的科技内容，周五发布。\n- 2025.04.25: 科技爱好者周刊（第 346 期）：未来就是永恒感的丧失, 这里记录每周值得分享的科技内容，周五发布。（[通知] 下周五一假期，周刊休息。）\n- 2025.04.18: 科技爱好者周刊（第 345 期）：HDMI 2.2 影音可能到头了, 这里记录每周值得分享的科技内容，周五发布。\n## 留言（65条）\n\n\nAllen\n\n\n 说：\n> 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n\n\nCS 在读本科生，“水课”作业、专业课实验和作业，乃至大作业或课程设计，或多或少都借助了 LLM，结果就是几乎什么都没学到。还是老老实实查文档、看课本，自己动手实现一遍来得更踏实，学到真知识的同时，也更有成就感。\n2025年5月23日 08:50 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446958) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nJason\n\n\n 说：\n"一家美国创业公司，准备发射卫星，将 AI 机房建在太空。\n\n\n\n\n\n它依靠24小时的太阳能供电，也不用担心散热。\n\n\n该公司希望通过这种方法，解决 AI 服务器的耗电和冷却问题。"\n\n\n在太空中没有空气对流，散热反而是很严重的问题，空气冷却没法用了。\n2025年5月23日 08:51 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446959) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n王二\n\n\n 说：\n沙特未来城很好地印证了加尔定律\n2025年5月23日 08:58 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446960) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n井花\n\n\n 说：\n> 芬兰尝试在驯鹿的鹿角，涂上荧光粉。\n\n\n原文英文是 reflective paint，应该是“反光涂料”，而不是“荧光粉”吧，即只会反光，不会自发光。\n2025年5月23日 09:12 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446961) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n钊\n\n\n 说：\n只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n\n\n运气成分很大呀\n2025年5月23日 09:14 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446962) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nAxxxxl\n\n\n 说：\n刘慈欣的《赡养上帝》就是讲了过分依赖过于成熟的技术，而完全丧失了对技术的理解。\n2025年5月23日 09:18 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446963) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n某网友\n\n\n 说：\n> ```\n> 引用Jason的发言：\n> ```\n> "一家美国创业公司，准备发射卫星，将 AI 机房建在太空。\n> 它依靠24小时的太阳能供电，也不用担心散热。\n> 该公司希望通过这种方法，解决 AI 服务器的耗电和冷却问题。"\n> 在太空中没有空气对流，散热反而是很严重的问题，空气冷却没法用了。\n\n\n太空温度极低，可以通过热辐射的方式散热，效果很好且无需介质。\n2025年5月23日 09:34 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446964) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nroland\n\n\n 说：\n就在用 zen 看博客\n2025年5月23日 09:36 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446965) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nNeoNeo\n\n\n 说：\n在某社交媒体上看到关于人工智能的评论，大意如下：  \n现在大学生用大模型提交论文，而学校用大模型检测学生的作文是否是自己写的。这种行为十分荒诞，简直就像是用自慰棒去插飞机杯。\n2025年5月23日 09:44 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446966) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nsunburst\n\n\n 说：\n人类已经使用他们不理解如何生产出来的铁器生活几千年了。只要文明不断层，后人随时会从文字记录中快速恢复过来。\n2025年5月23日 09:45 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446967) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\ndousha\n\n\n 说：\n在太空中虽然没有空气对流，但是黑体辐射的散热效率会有很大的提升（散热功率 ≈ 散热表面积 * 玻尔兹曼常数 * 温度差^4）。如果目标温度是 20 摄氏度的话，甚至还得考虑给内部环境加热的情况。\n\n\n其实我个人更在意的情况是网络延迟和带宽问题，毕竟如果想要提高散热效率就得放到更高的轨道，更高的轨道就会有更高的延迟和更窄的带宽。这样一搞无论是训练还是推理貌似都很成问题。\n2025年5月23日 09:46 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446968) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nsygkyo\n\n\n 说：\n1986年，同龄人的我，还在为生活而苟且\n2025年5月23日 09:51 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446969) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nxxxx\n\n\n 说：\n> ```\n> 引用某网友的发言：\n> ```\n> 太空温度极低，可以通过热辐射的方式散热，效果很好且无需介质。\n\n\n太空热辐射散热，散热效率很慢的。特别慢。\n2025年5月23日 10:00 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446970) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nschummy\n\n\n 说：\nAI的核心代码我觉得9行多了，一行就可以：\n\n\nllm(msg)\n2025年5月23日 10:01 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446971) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nAllin\n\n\n 说：\n只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n\n\n一个人的命运,既要考虑个人的奋斗,也要考虑历史的进程\n2025年5月23日 10:04 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446972) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n铁腕\n\n\n 说：\n> ```\n> 引用Jason的发言：\n> ```\n> "一家美国创业公司，准备发射卫星，将 AI 机房建在太空。\n> 它依靠24小时的太阳能供电，也不用担心散热。\n> 该公司希望通过这种方法，解决 AI 服务器的耗电和冷却问题。"\n> 在太空中没有空气对流，散热反而是很严重的问题，空气冷却没法用了。\n\n\n问了下豆包散热的问题，得到的回复是太空飞行器一般通过辐射散热。感觉这个太空服务器主要还是通信性能和维护成本方面存在问题，就是把一般服务器的用电成本换成了发射成本+特殊材料+高折损率，规模上去的话理论上是有可能把单价打平甚至逆袭。就是到时候又会有其他问题了，比如造成太空垃圾泛滥\n2025年5月23日 10:13 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446973) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nMing\n\n\n 说：\n> ```\n> 引用钊的发言：\n> ```\n> 只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n> 运气成分很大呀\n\n\n必然藏在偶然之中\n2025年5月23日 10:14 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446974) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n老牛\n\n\n 说：\n"我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。"\n\n\n工作中也经常用，只要把GPT当成自己思考的补充，而不是替代自己思考，那问题不大。\n2025年5月23日 10:20 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446975) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nwalker\n\n\n 说：\n> ```\n> 引用某网友的发言：\n> ```\n> 太空温度极低，可以通过热辐射的方式散热，效果很好且无需介质。\n\n\n\n是的, 热传递的三种试, 传导对流辐射, 只身下辐射了, 在太空中早就广泛应用了, 只是局限很大, 对流是能最快带走热量的方式, 辐射不能, 而且还要建巨大的辐射面板\n2025年5月23日 10:28 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446976) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nPlasterer\n\n\n 说：\n“伊尔亚·苏茨克维出生于前苏联，后去了以色列，然后来到加拿大。他是亚历克斯·克里泽夫斯基在多伦多大学的博士同学，也是辛顿的博士生。”\n\n\n你说 伊尔亚 ，不看照片，不知道是谁  \n你要说 伊利亚 ，一下子就知道是谁了\n2025年5月23日 10:29 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446977) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n996牛马\n\n\n 说：\n【我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。】  \n很赞同，AI应该是辅助工具，不是替代工具。就像作业直接抄答案，虽然任务完成了，但是自身却没有掌握里面的知识。\n2025年5月23日 10:36 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446978) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nsun\n\n\n 说：\n> ```\n> 引用Jason的发言：\n> ```\n> "一家美国创业公司，准备发射卫星，将 AI 机房建在太空。\n> 它依靠24小时的太阳能供电，也不用担心散热。\n> 该公司希望通过这种方法，解决 AI 服务器的耗电和冷却问题。"\n> 在太空中没有空气对流，散热反而是很严重的问题，空气冷却没法用了。\n\n\n确实，真空中建立AI机房的话，不仅要考虑减少太阳辐射，还要考虑主动将自身的能量辐射出去\n2025年5月23日 10:54 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446980) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\ndaming\n\n\n 说：\n> ```\n> 引用Allen的发言：\n> ```\n> > 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n> CS 在读本科生，“水课”作业、专业课实验和作业，乃至大作业或课程设计，或多或少都借助了 LLM，结果就是几乎什么都没学到。还是老老实实查文档、看课本，自己动手实现一遍来得更踏实，学到真知识的同时，也更有成就感。\n\n\n电脑搜索出来前，大家都在图书馆里查资料呢\n2025年5月23日 10:54 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446981) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\ngene\n\n\n 说：\nslack.com/is/wherever-you-are 已被做了重定向。  \nslack 官网的介绍页面还是  [https://slack.com/about](https://slack.com/about)\n2025年5月23日 11:02 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446982) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nMiracleWong\n\n\n 说：\n> ```\n> 引用roland的发言：\n> ```\n> 就在用 zen 看博客\n\n\n+1 特地下载了Zen 来使用下\n2025年5月23日 11:03 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446983) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nsun\n\n\n 说：\n> ```\n> 引用Allin的发言：\n> ```\n> 只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n> 一个人的命运,既要考虑个人的奋斗,也要考虑历史的进程\n\n\n突然想起《鬼吹灯》里的一句话，“摸金校尉，合则生，分则死”。回过头来看看李飞飞、辛顿和黄仁勋的个人历程，李飞飞因为imagenet项目差点没法毕业，辛顿因为第三次人工智能寒冬沉寂了20年，老黄当年做nvidia芯片好像也是破釜沉舟，三个前途未知的人碰到了一起，AI时代来临了。他们造就了时代，时代也成就了他们。真奇妙啊！\n2025年5月23日 11:05 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446984) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nAzureSky_X\n\n\n 说：\n> ```\n> 引用Allen的发言：\n> ```\n> > 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n> CS 在读本科生，“水课”作业、专业课实验和作业，乃至大作业或课程设计，或多或少都借助了 LLM，结果就是几乎什么都没学到。还是老老实实查文档、看课本，自己动手实现一遍来得更踏实，学到真知识的同时，也更有成就感。\n\n\n之前是这样的，但其实在DeepSeek-R1模型推出之后，我觉得这种状况有所缓解。因为推理类的模型默认输出模型思考链。就相当于，我们不仅有了名师给的答案，还有了他的思考逻辑（虽然不一定适用于自身）。个人觉得遇到一个未涉足的领域问题，最难的不是实施阶段的“怎么做”，而是问题我该怎么切入，我应该“怎么问”才能获取到我应该知道的知识，哪些知识是这个问题上我需要知道的？哪怕遇到推理模型的思考链对于一些知识点一笔带过，我们也能从中提取“怎么问”的关键词，自己获取答案。\n2025年5月23日 11:20 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446985) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nCharles\n\n\n 说：\n最近仔细看了下周刊下面的评论，感觉很有意思，阮大是否有群可以加入，或者考虑新建一个群，能认识下兴趣相投的人\n2025年5月23日 11:21 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446986) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\ntomzheng\n\n\n 说：\n需要封闭环境才能杜绝AI\n2025年5月23日 11:23 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446987) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nSul\n\n\n 说：\n> 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n\n\n实际这个世界本来也不需要那么多“学到”什么的人。无论用什么方法学，聪明人大部分最后还是聪明人，少数会变成普通人。普通人绝大多数还是会成为普通人，少数会变成聪明人。这个世界要发展，至少现阶段并不需要太多聪明人的。\n\n\n特别是大语言模型并没有强制规范怎么去学，只是提供了多一种方式而已。\n2025年5月23日 11:32 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446988) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nGao\n\n\n 说：\n> 我们很快会跟大家分享一个低调的研究成果。我们会给它起一个比 chatGPT 更好的名字，以防它流行起来。\n\n\n取一个有利于传播的名字不是更好吗？为什么要防止它流行起来？\n2025年5月23日 11:35 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446989) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nSul\n\n\n 说：\n> ```\n> 引用sun的发言：\n> ```\n> 确实，真空中建立AI机房的话，不仅要考虑减少太阳辐射，还要考虑主动将自身的能量辐射出去\n\n\n直接用空调原理就行了把，用氟利昂类但适合太空环境的冷却剂在设施内外传递热量，设施内部整个就是一个大的空调翅片，主板带cpu直接贴在散热片上，散热片主动制冷。散热片的热量用氟利昂带到设施外面。外面的散热装置通过自转或遮挡始终保持在背向太阳的一面，反正面积大，温差大，就直接辐射散热。\n2025年5月23日 11:44 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446990) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nSimon\n\n\n 说：\n为什么不用考虑散热问题，太空最需要考虑的就是散热问题了，你建的机房产热这么多，得多大的散热板去热辐射啊。\n2025年5月23日 11:45 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446991) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nmenglj\n\n\n 说：\n真空环境下，散热可是老大难问题。\n2025年5月23日 12:17 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446993) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n规划分局\n\n\n 说：\n“我们很快会跟大家分享一个低调的研究成果。我们会给它起一个比 chatGPT 更好的名字，以防它流行起来。”Altman不愧是殿堂级的宣传营销大师。  \n之前就感觉，他和他的员工，经常在网上发表一些故弄玄虚、装神弄鬼的言论。  \n这些云遮雾绕的言论还真不是没用，至少成功把之前大公司发展AI模型的方向引歪了，大家都狂堆算力。  \n最后DeepSeek这个愣头青小公司（相对而言）却把OpenAI最关键的、想尽办法藏着掖着的最核心思路开源了，也就是MoE。  \n事后OpenAI才扭扭捏捏承认,自己其实早就发现这个东西。  \n虽然商业竞争无可厚非，但起个Open的名字实在反讽了些。  \n不过，现在看起来，Altman的发言风格还是老一套，还是那副“旷世高人”的老神仙模样，继续忽悠大法。  \n可能美国环境特殊，我印象中，美式商业理论非常推崇这种能说会道、满口谎言的“人才”，毕竟等到别人发现不对劲的时候，你早就已经赚饱跑路，去做下一桩买卖了。\n2025年5月23日 12:25 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446994) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nnieha\n\n\n 说：\n> ```\n> 引用Allen的发言：\n> ```\n> > 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n> CS 在读本科生，“水课”作业、专业课实验和作业，乃至大作业或课程设计，或多或少都借助了 LLM，结果就是几乎什么都没学到。还是老老实实查文档、看课本，自己动手实现一遍来得更踏实，学到真知识的同时，也更有成就感。\n\n\n不管是查文档、看课本还是动手实现，都可以通过 AI 辅助，节省时间。重点在于要理解 AI 在说什么，而不是生搬硬套。\n2025年5月23日 12:50 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446996) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n匿名\n\n\n 说：\n"一家美国创业公司，准备发射卫星，将 AI 机房建在太空。\n\n\n它依靠24小时的太阳能供电，也不用担心散热。\n\n\n该公司希望通过这种方法，解决 AI 服务器的耗电和冷却问题。"\n\n\n看看中国的，已经上天的卫星吧。\n\n\n[https://news.cctv.cn/2025/05/15/ARTIczUfaHq0py6G97rC2MHU250515.shtml](https://news.cctv.cn/2025/05/15/ARTIczUfaHq0py6G97rC2MHU250515.shtml)\n\n\n实际上，这种计算卫星可以用于在太空上计算其他卫星的数据。\n2025年5月23日 13:11 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446997) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nk88936\n\n\n 说：\n这一期的评论区很有深度啊\n2025年5月23日 13:15 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446998) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nkiFte\n\n\n 说：\n> ```\n> 引用Allen的发言：\n> ```\n> > 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n\n\n咱学前端的体验也是这样。。。  \n已经可以用ai花大量时间从零搓一个像模像样的独立站了。  \n但是让自己抛开ai写...我就完全想不到那些画面效果该怎么实现。\n2025年5月23日 13:52 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-446999) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n骑自行车不穿裤衩\n\n\n 说：\n我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n\n\n最终可能会出现这样一代人，自己的智力很低下，完全依赖于他们不理解的技术，一旦技术崩溃，他们永远无法从头开始重建。\n\n\n没啥问题吧，他们的智力会放在其它地方啊。不是每个人都需要知道芯片怎么造出来的，汽车怎么造出来的\n2025年5月23日 14:05 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447000) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n橘下楼\n\n\n 说：\n`只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。`\n\n\n我看大家都对这一句话有感触。  \n我理解是：这么高浓度的人才聚集在硅谷，如此优化的风投运作机制, 即使英伟达不出现高新能显卡。  \n其他公司或者团队估计也会攒一个硬件。  \n将以上的东西总结为土壤，那么只要这个土壤长时间保持肥沃，有良好的循环，一两个好的idea就像是种子一样，落到土壤里就会快速成长和发芽。至于这个种子最后可以长多高多壮大，那就看这个种子内生的生长力。\n\n\n这上面的过程叫做创新。是的，创新就是这么一回事。把人才，资金，时间，软件，硬件，一大堆东西放在一个缸里，搅拌搅拌，指不定就搞出个什么好玩意儿。\n\n\n这不是说我们国内就没有，杭州不久在学习这样搞么。  \n别急，等吧。\n2025年5月23日 14:15 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447001) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nyaohk\n\n\n 说：\n突然联想到有些出土的工艺是现在人无法做到的。若干年后的人会不会也惊叹当前的技术呢。\n2025年5月23日 14:21 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447003) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\ntnt\n\n\n 说：\n`只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。`  \n我觉得更像是这几个条件漫长的互相等待吧，并不是同时出现。  \n引用一下ai整理的关键年份：  \n各个关键技术和数据集的首次出现年份大致如下：\n\n\n神经网络算法:\n\n\n理论模型: 1943年，Warren McCulloch和Walter Pitts提出了第一个抽象的神经元模型（M-P模型）。  \n感知机（Perceptron）: 1957年，Frank Rosenblatt发明了第一个可训练的神经网络——感知机。  \n反向传播算法（Backpropagation）: 虽然概念在1974年Paul Werbos的博士论文中有所提及，但在1980年代中期，由Rumelhart、Hinton和Williams等人的工作使其得到广泛应用。  \n深度信念网络（Deep Belief Networks）: 2006年，Geoffrey Hinton发表论文，提出了“深度信念网络”的概念，标志着深度学习的复苏。  \nImageNet 训练集:\n\n\n项目启动与首次发布: ImageNet项目由李飞飞团队于2006年启动，并于2009年首次公开发布了包含数百万张图像和数万个类别的ImageNet数据库。  \nImageNet 大规模视觉识别挑战赛 (ILSVRC): 于2010年开始举办。  \nNVIDIA 高速显卡（GPU 与 CUDA）:\n\n\nGPU 概念提出: NVIDIA在1999年发布GeForce 256时首次提出了GPU（图形处理器）的概念。  \nCUDA 发布: NVIDIA的并行计算平台CUDA（Compute Unified Device Architecture）于2007年2月首次发布。它使得开发者能够利用GPU进行通用计算，为后来的深度学习加速奠定了基础。  \n综上所述，虽然这些要素在2012年达到一个结合的巅峰，并催生了深度学习的爆发，但它们各自的起源和发展都远早于2012年。\n2025年5月23日 15:03 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447004) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nEthan\n\n\n 说：\n> 最终可能会出现这样一代人，自己的智力很低下，完全依赖于他们不理解的技术，一旦技术崩溃，他们永远无法从头开始重建。\n\n\n我们还依赖编译器呢，现在有几个人会写汇编码？一旦世界上所有编译器崩溃，有几个人会编译？无稽之谈\n2025年5月23日 15:28 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447006) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nEthan\n\n\n 说：\n> 最近仔细看了下周刊下面的评论，感觉很有意思，阮大是否有群可以加入，或者考虑新建一个群，能认识下兴趣相投的人\n\n\n双手双脚同意，阮大可以组建一个活跃的技术社区/群\n2025年5月23日 15:31 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447007) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n一个正常人\n\n\n 说：\n"我们很快会跟大家分享一个低调的研究成果。我们会给它起一个比 chatGPT 更好的名字，以防它流行起来。"\n\n\n不愧为商业鬼才\n2025年5月23日 15:46 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447008) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n180554\n\n\n 说：\n如果ai能百分之百的完成这个东西，复制过来就能用，为什么还要人学习技术细节呢？直接用不就好了吗？  \n担心ai服务崩溃，技术资料全部消失，这比外星人入侵还要天方夜谭  \nai本来就是解放人类，节省人类的时间成本的，何况如果想学真东西，有ai辅助，学习成本也能大大降低\n2025年5月23日 16:12 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447009) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nAllen\n\n\n 说：\n> ```\n> 引用kiFte的发言：\n> ```\n> 咱学前端的体验也是这样。。。  \n> 已经可以用ai花大量时间从零搓一个像模像样的独立站了。  \n> 但是让自己抛开ai写...我就完全想不到那些画面效果该怎么实现。\n\n\n是的，我就是担心自己过分依赖于 AI，对 AI 生成的东西一知半解，甚至无法区分正确与否，脱离了 AI 就几乎不能自己从头实现一个项目。\n\n\n不过有些时候 LLM 确实是很有用的：比如把文档喂给它，快速筛选出我想要的参数；或者生成一些简单好用的脚本；也能辅助我阅读项目源码等等。\n\n\n总的来说，要用好 AI 来提升学习和工作效率的话，我觉得应真正理解 LLM 给出的内容，区分它什么时候在胡言乱语，不依赖 AI，多过过脑子才是最重要的。\n2025年5月23日 16:30 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447010) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n1\n\n\n 说：\n> ```\n> 引用Charles的发言：\n> ```\n> 最近仔细看了下周刊下面的评论，感觉很有意思，阮大是否有群可以加入，或者考虑新建一个群，能认识下兴趣相投的人\n\n\n何不留下VX  自己建群\n2025年5月23日 16:58 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447011) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nwww\n\n\n 说：\n我觉的 雨果。德。加里斯(Hugo de Garis) 才是 真AI 的唯一创始人。\n2025年5月23日 17:23 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447012) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nBaiyssy\n\n\n 说：\n印象里费曼说过，人类一直在对世界一无所知中生活。  \n从来没有人真的理解自己依赖的技术，甚至可以说，理解这些技术、可以理解这些技术不过是一种虚妄的幻觉。\n2025年5月23日 18:08 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447013) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nWooooo\n\n\n 说：\n> ```\n> 引用Gao的发言：\n> ```\n> > 我们很快会跟大家分享一个低调的研究成果。我们会给它起一个比 chatGPT 更好的名字，以防它流行起来。\n> 取一个有利于传播的名字不是更好吗？为什么要防止它流行起来？\n\n\n应该是翻译问题，“得起个好名，万一火了呢”\n2025年5月24日 22:40 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447016) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nLZDPP\n\n\n 说：\nLLM的流行会像人们展示实践的重要性，如果从现代的理论来表述的话。知识分为「陈述性知识」和「程序性知识」，LLM只解决了「陈述性知识」，但是「程序性知识」”需要实践来获得。\n2025年5月25日 12:58 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447017) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nSHMO\n\n\n 说：\n> ```\n> 引用Allen的发言：\n> ```\n> > 我关注了一些教育工作者，他们都报告了同样的现象：他们的学生什么事情都用 ChatGPT，结果什么也没学到。\n> CS 在读本科生，“水课” 作业、专业课实验和作业，乃至大作业或课程设计，或多或少都借助了 LLM，结果就是几乎什么都没学到。还是老老实实查文档、看课本，自己动手实现一遍来得更踏实，学到真知识的同时，也更有成就感。\n\n\n大模型AI之前就存在复制粘贴“缝合怪”，这个现象一直就存在，并不是AI导致了这个现象，只是降低了门槛。\n2025年5月25日 21:17 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447018) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nGregg\n\n\n 说：\n请问有使用Zen Browser时，即时有开启VPN，但无法访问国外网站的问题吗？比如说Github Gmail等\n2025年5月26日 09:17 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447019) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n某网友\n\n\n 说：\n> ```\n> 引用某网友的发言：\n> ```\n> 太空温度极低，可以通过热辐射的方式散热，效果很好且无需介质。\n\n\n“效果很好”是对比什么？\n2025年5月26日 10:34 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447020) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nJ.Cooper\n\n\n 说：\n可以把AI当成一个有很多wheels的一个,wheels博物馆,需要什么就去取用,只要是为了完成你自己的car,当然你也要知道这个wheel的参数等各种信息,现在这个时代感觉就是要用ai来提升自己上手某件事情的速度,感觉世界就是一个巨大的草台班子,没人可以保证自己懂得自己用的所有技术@_@\n2025年5月26日 11:35 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447022) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n路人甲\n\n\n 说：\n机房建太空其实能源是更大的问题  \n近地轨道假定和地球差不多， [WP上的数据是 1361 W/m^2](https://en.wikipedia.org/wiki/Solar_irradiance#At_the_top_of_Earth\'s_atmosphere) ，太阳能板的转化效率给他放高一点25%，发电效率是340W/m^2，而20℃的辐射散热片向3K背景辐射的效率是418W/m^2，还能双面散热。也就是说不到太阳能板一半的面积的辐射散热片就能处理散热问题了。  \n散热不是很大的问题，因为太空中只靠太阳能板即发即用， 能源就不多，而你的散热需求差不多就是发电量等量，不是吗？ （更不用说如果不放在日地拉格朗日点的话，在背光面不发电但散热……）\n\n\n其实另外还有一个问题，宇宙射线导致的位翻转怎么处理。训练AI的容错度比较高吗？\n2025年5月26日 14:58 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447023) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nろんな先生\n\n\n 说：\n> ```\n> 引用schummy的发言：\n> ```\n> AI的核心代码我觉得9行多了，一行就可以：\n> llm(msg)\n\n\n一行不成，不能把本地权限全权交给llm，至少得做个本地代理\n2025年5月26日 14:59 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447024) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nken\n\n\n 说：\n> ```\n> 引用钊的发言：\n> ```\n> 只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n> 运气成分很大呀\n\n\n生命的出现运气成分更大\n2025年5月26日 16:35 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447026) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nyanmin\n\n\n 说：\n> ```\n> 引用钊的发言：\n> ```\n> 只有等到2012年，才万事俱备。神经网络算法 + 李飞飞的 ImageNet 训练集 + Nvidia 高速显卡，同时出现了。\n> 运气成分很大呀\n\n\n成功永远少了运气，最后一块儿拼图\n2025年5月26日 22:05 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447027) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nyanmin\n\n\n 说：\n> ```\n> 引用Charles的发言：\n> ```\n> 最近仔细看了下周刊下面的评论，感觉很有意思，阮大是否有群可以加入，或者考虑新建一个群，能认识下兴趣相投的人\n\n\n其实这样最好，有点想法，大家就写下来，而且还可以保存。群里事情大家的话不多的，最后都变成了死群，而且大家说的话很多留不下来。\n2025年5月26日 22:11 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447028) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\ngaomengyu\n\n\n 说：\n> ```\n> 引用Ethan的发言：\n> ```\n> > 最近仔细看了下周刊下面的评论，感觉很有意思，阮大是否有群可以加入，或者考虑新建一个群，能认识下兴趣相投的人\n> 双手双脚同意，阮大可以组建一个活跃的技术社区/群\n\n\n在 《网络社区的悲剧》 那一期阮老师讲过为什么不建社区/群的原因。\n2025年5月27日 08:38 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447029) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nAlex\n\n\n 说：\n> ```\n> 引用ken的发言：\n> ```\n> 生命的出现运气成分更大\n\n\n这世界不是偶然的，造物主是存在的，游戏继续~~~ :D\n2025年5月27日 11:02 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447031) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\nnero\n\n\n 说：\n> ```\n> 引用yanmin的发言：\n> ```\n> 其实这样最好，有点想法，大家就写下来，而且还可以保存。群里事情大家的话不多的，最后都变成了死群，而且大家说的话很多留不下来。\n\n\n建群后最终会变成吹牛水群，很多技术群都是这样的\n2025年5月27日 11:52 \n |  [#](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-447032) \n |  [引用](http://www.ruanyifeng.com/blog/2025/05/weekly-issue-349.html#comment-text)\n## 我要发表看法\n\n\n您的留言\n                    （HTML标签部分可用）\n您的大名：\n\n\n«-必填\n电子邮件：\n\n\n«-必填，不公开\n个人网址：\n\n\n«-我信任你，不会填写广告链接\n记住个人信息？\n\n\n正在发表您的评论，请稍候\n«- 点击按钮'
  const editorRef = useTiptapEditor({
    content,
    editable: false
  });
  return <div style={{ 
    width: '100%', 
    height: '500px',
    overflow: 'auto',
    border: '1px solid #ccc'
  }}>
    <TiptapReader editorRef={editorRef} />
  </div>
}
```